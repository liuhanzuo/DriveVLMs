{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22d0b692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/transformers/models/auto/image_processing_auto.py:604: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoModelForCausalLM\n",
    "from drivevlms.models.phi4_bjxx import Phi4MMProcessor\n",
    "from drivevlms.build import build_collate_fn\n",
    "from llmcompressor import oneshot\n",
    "from llmcompressor.modifiers.quantization import GPTQModifier\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58274458",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = f\"../data/models/{MODEL_ID.split('/')[-1]}-W4A16-G128\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a3bb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.84it/s]\n",
      "Some weights of Phi4MMForCausalLM were not initialized from the model checkpoint at cutebananas/phi-4-multimodal-finetuned and are newly initialized: ['model.embed_tokens_extend.audio_embed.audio_projection.speech.0.bias', 'model.embed_tokens_extend.audio_embed.audio_projection.speech.0.weight', 'model.embed_tokens_extend.audio_embed.audio_projection.speech.2.bias', 'model.embed_tokens_extend.audio_embed.audio_projection.speech.2.weight', 'model.embed_tokens_extend.audio_embed.audio_projection.vision.0.bias', 'model.embed_tokens_extend.audio_embed.audio_projection.vision.0.weight', 'model.embed_tokens_extend.audio_embed.audio_projection.vision.2.bias', 'model.embed_tokens_extend.audio_embed.audio_projection.vision.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.embed.conv.0.bias', 'model.embed_tokens_extend.audio_embed.encoder.embed.conv.0.weight', 'model.embed_tokens_extend.audio_embed.encoder.embed.conv.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.embed.conv.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.embed.conv.3.bias', 'model.embed_tokens_extend.audio_embed.encoder.embed.conv.3.weight', 'model.embed_tokens_extend.audio_embed.encoder.embed.conv.5.bias', 'model.embed_tokens_extend.audio_embed.encoder.embed.conv.5.weight', 'model.embed_tokens_extend.audio_embed.encoder.embed.conv.6.bias', 'model.embed_tokens_extend.audio_embed.encoder.embed.conv.6.weight', 'model.embed_tokens_extend.audio_embed.encoder.embed.out.bias', 'model.embed_tokens_extend.audio_embed.encoder.embed.out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoder_embedding.global_invstd', 'model.embed_tokens_extend.audio_embed.encoder.encoder_embedding.global_mean', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.0.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.1.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.10.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.11.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.12.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.13.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.14.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.15.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.16.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.17.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.18.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.19.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.2.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.20.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.21.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.22.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.23.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.3.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.4.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.5.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.6.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.7.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.8.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.conv.dw_sep_conv_1d.dw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.conv.dw_sep_conv_1d.dw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.conv.dw_sep_conv_1d.pw_conv.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.conv.dw_sep_conv_1d.pw_conv.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.conv.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.conv.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.conv.glu.b1', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.conv.glu.b2', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.conv.glu.ext_pw_conv_1d.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.conv.glu.ext_pw_conv_1d.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.conv.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.conv.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.feed_forward_in.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.feed_forward_in.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.feed_forward_in.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.feed_forward_in.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.feed_forward_in.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.feed_forward_in.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.feed_forward_out.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.feed_forward_out.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.feed_forward_out.net.0.linear.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.feed_forward_out.net.0.linear.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.feed_forward_out.net.2.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.feed_forward_out.net.2.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.layer_norm.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.layer_norm.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.layer_norm_att.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.layer_norm_att.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.self_attn.linear_k.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.self_attn.linear_k.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.self_attn.linear_out.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.self_attn.linear_out.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.self_attn.linear_q.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.self_attn.linear_q.weight', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.self_attn.linear_v.bias', 'model.embed_tokens_extend.audio_embed.encoder.encoders.9.self_attn.linear_v.weight', 'model.embed_tokens_extend.audio_embed.encoder.relative_attention_bias_layer.bias_values.weight', 'model.layers.0.mlp.down_proj.lora_A.speech.weight', 'model.layers.0.mlp.down_proj.lora_B.speech.weight', 'model.layers.0.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.0.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.0.self_attn.o_proj.lora_A.speech.weight', 'model.layers.0.self_attn.o_proj.lora_B.speech.weight', 'model.layers.0.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.0.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.1.mlp.down_proj.lora_A.speech.weight', 'model.layers.1.mlp.down_proj.lora_B.speech.weight', 'model.layers.1.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.1.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.1.self_attn.o_proj.lora_A.speech.weight', 'model.layers.1.self_attn.o_proj.lora_B.speech.weight', 'model.layers.1.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.1.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.10.mlp.down_proj.lora_A.speech.weight', 'model.layers.10.mlp.down_proj.lora_B.speech.weight', 'model.layers.10.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.10.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.10.self_attn.o_proj.lora_A.speech.weight', 'model.layers.10.self_attn.o_proj.lora_B.speech.weight', 'model.layers.10.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.10.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.11.mlp.down_proj.lora_A.speech.weight', 'model.layers.11.mlp.down_proj.lora_B.speech.weight', 'model.layers.11.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.11.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.11.self_attn.o_proj.lora_A.speech.weight', 'model.layers.11.self_attn.o_proj.lora_B.speech.weight', 'model.layers.11.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.11.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.12.mlp.down_proj.lora_A.speech.weight', 'model.layers.12.mlp.down_proj.lora_B.speech.weight', 'model.layers.12.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.12.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.12.self_attn.o_proj.lora_A.speech.weight', 'model.layers.12.self_attn.o_proj.lora_B.speech.weight', 'model.layers.12.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.12.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.13.mlp.down_proj.lora_A.speech.weight', 'model.layers.13.mlp.down_proj.lora_B.speech.weight', 'model.layers.13.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.13.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.13.self_attn.o_proj.lora_A.speech.weight', 'model.layers.13.self_attn.o_proj.lora_B.speech.weight', 'model.layers.13.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.13.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.14.mlp.down_proj.lora_A.speech.weight', 'model.layers.14.mlp.down_proj.lora_B.speech.weight', 'model.layers.14.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.14.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.14.self_attn.o_proj.lora_A.speech.weight', 'model.layers.14.self_attn.o_proj.lora_B.speech.weight', 'model.layers.14.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.14.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.15.mlp.down_proj.lora_A.speech.weight', 'model.layers.15.mlp.down_proj.lora_B.speech.weight', 'model.layers.15.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.15.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.15.self_attn.o_proj.lora_A.speech.weight', 'model.layers.15.self_attn.o_proj.lora_B.speech.weight', 'model.layers.15.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.15.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.16.mlp.down_proj.lora_A.speech.weight', 'model.layers.16.mlp.down_proj.lora_B.speech.weight', 'model.layers.16.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.16.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.16.self_attn.o_proj.lora_A.speech.weight', 'model.layers.16.self_attn.o_proj.lora_B.speech.weight', 'model.layers.16.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.16.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.17.mlp.down_proj.lora_A.speech.weight', 'model.layers.17.mlp.down_proj.lora_B.speech.weight', 'model.layers.17.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.17.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.17.self_attn.o_proj.lora_A.speech.weight', 'model.layers.17.self_attn.o_proj.lora_B.speech.weight', 'model.layers.17.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.17.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.18.mlp.down_proj.lora_A.speech.weight', 'model.layers.18.mlp.down_proj.lora_B.speech.weight', 'model.layers.18.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.18.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.18.self_attn.o_proj.lora_A.speech.weight', 'model.layers.18.self_attn.o_proj.lora_B.speech.weight', 'model.layers.18.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.18.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.19.mlp.down_proj.lora_A.speech.weight', 'model.layers.19.mlp.down_proj.lora_B.speech.weight', 'model.layers.19.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.19.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.19.self_attn.o_proj.lora_A.speech.weight', 'model.layers.19.self_attn.o_proj.lora_B.speech.weight', 'model.layers.19.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.19.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.2.mlp.down_proj.lora_A.speech.weight', 'model.layers.2.mlp.down_proj.lora_B.speech.weight', 'model.layers.2.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.2.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.2.self_attn.o_proj.lora_A.speech.weight', 'model.layers.2.self_attn.o_proj.lora_B.speech.weight', 'model.layers.2.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.2.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.20.mlp.down_proj.lora_A.speech.weight', 'model.layers.20.mlp.down_proj.lora_B.speech.weight', 'model.layers.20.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.20.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.20.self_attn.o_proj.lora_A.speech.weight', 'model.layers.20.self_attn.o_proj.lora_B.speech.weight', 'model.layers.20.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.20.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.21.mlp.down_proj.lora_A.speech.weight', 'model.layers.21.mlp.down_proj.lora_B.speech.weight', 'model.layers.21.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.21.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.21.self_attn.o_proj.lora_A.speech.weight', 'model.layers.21.self_attn.o_proj.lora_B.speech.weight', 'model.layers.21.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.21.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.22.mlp.down_proj.lora_A.speech.weight', 'model.layers.22.mlp.down_proj.lora_B.speech.weight', 'model.layers.22.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.22.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.22.self_attn.o_proj.lora_A.speech.weight', 'model.layers.22.self_attn.o_proj.lora_B.speech.weight', 'model.layers.22.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.22.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.23.mlp.down_proj.lora_A.speech.weight', 'model.layers.23.mlp.down_proj.lora_B.speech.weight', 'model.layers.23.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.23.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.23.self_attn.o_proj.lora_A.speech.weight', 'model.layers.23.self_attn.o_proj.lora_B.speech.weight', 'model.layers.23.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.23.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.24.mlp.down_proj.lora_A.speech.weight', 'model.layers.24.mlp.down_proj.lora_B.speech.weight', 'model.layers.24.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.24.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.24.self_attn.o_proj.lora_A.speech.weight', 'model.layers.24.self_attn.o_proj.lora_B.speech.weight', 'model.layers.24.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.24.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.25.mlp.down_proj.lora_A.speech.weight', 'model.layers.25.mlp.down_proj.lora_B.speech.weight', 'model.layers.25.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.25.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.25.self_attn.o_proj.lora_A.speech.weight', 'model.layers.25.self_attn.o_proj.lora_B.speech.weight', 'model.layers.25.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.25.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.26.mlp.down_proj.lora_A.speech.weight', 'model.layers.26.mlp.down_proj.lora_B.speech.weight', 'model.layers.26.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.26.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.26.self_attn.o_proj.lora_A.speech.weight', 'model.layers.26.self_attn.o_proj.lora_B.speech.weight', 'model.layers.26.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.26.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.27.mlp.down_proj.lora_A.speech.weight', 'model.layers.27.mlp.down_proj.lora_B.speech.weight', 'model.layers.27.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.27.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.27.self_attn.o_proj.lora_A.speech.weight', 'model.layers.27.self_attn.o_proj.lora_B.speech.weight', 'model.layers.27.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.27.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.28.mlp.down_proj.lora_A.speech.weight', 'model.layers.28.mlp.down_proj.lora_B.speech.weight', 'model.layers.28.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.28.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.28.self_attn.o_proj.lora_A.speech.weight', 'model.layers.28.self_attn.o_proj.lora_B.speech.weight', 'model.layers.28.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.28.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.29.mlp.down_proj.lora_A.speech.weight', 'model.layers.29.mlp.down_proj.lora_B.speech.weight', 'model.layers.29.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.29.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.29.self_attn.o_proj.lora_A.speech.weight', 'model.layers.29.self_attn.o_proj.lora_B.speech.weight', 'model.layers.29.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.29.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.3.mlp.down_proj.lora_A.speech.weight', 'model.layers.3.mlp.down_proj.lora_B.speech.weight', 'model.layers.3.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.3.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.3.self_attn.o_proj.lora_A.speech.weight', 'model.layers.3.self_attn.o_proj.lora_B.speech.weight', 'model.layers.3.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.3.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.30.mlp.down_proj.lora_A.speech.weight', 'model.layers.30.mlp.down_proj.lora_B.speech.weight', 'model.layers.30.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.30.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.30.self_attn.o_proj.lora_A.speech.weight', 'model.layers.30.self_attn.o_proj.lora_B.speech.weight', 'model.layers.30.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.30.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.31.mlp.down_proj.lora_A.speech.weight', 'model.layers.31.mlp.down_proj.lora_B.speech.weight', 'model.layers.31.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.31.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.31.self_attn.o_proj.lora_A.speech.weight', 'model.layers.31.self_attn.o_proj.lora_B.speech.weight', 'model.layers.31.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.31.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.4.mlp.down_proj.lora_A.speech.weight', 'model.layers.4.mlp.down_proj.lora_B.speech.weight', 'model.layers.4.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.4.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.4.self_attn.o_proj.lora_A.speech.weight', 'model.layers.4.self_attn.o_proj.lora_B.speech.weight', 'model.layers.4.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.4.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.5.mlp.down_proj.lora_A.speech.weight', 'model.layers.5.mlp.down_proj.lora_B.speech.weight', 'model.layers.5.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.5.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.5.self_attn.o_proj.lora_A.speech.weight', 'model.layers.5.self_attn.o_proj.lora_B.speech.weight', 'model.layers.5.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.5.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.6.mlp.down_proj.lora_A.speech.weight', 'model.layers.6.mlp.down_proj.lora_B.speech.weight', 'model.layers.6.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.6.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.6.self_attn.o_proj.lora_A.speech.weight', 'model.layers.6.self_attn.o_proj.lora_B.speech.weight', 'model.layers.6.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.6.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.7.mlp.down_proj.lora_A.speech.weight', 'model.layers.7.mlp.down_proj.lora_B.speech.weight', 'model.layers.7.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.7.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.7.self_attn.o_proj.lora_A.speech.weight', 'model.layers.7.self_attn.o_proj.lora_B.speech.weight', 'model.layers.7.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.7.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.8.mlp.down_proj.lora_A.speech.weight', 'model.layers.8.mlp.down_proj.lora_B.speech.weight', 'model.layers.8.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.8.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.8.self_attn.o_proj.lora_A.speech.weight', 'model.layers.8.self_attn.o_proj.lora_B.speech.weight', 'model.layers.8.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.8.self_attn.qkv_proj.lora_B.speech.weight', 'model.layers.9.mlp.down_proj.lora_A.speech.weight', 'model.layers.9.mlp.down_proj.lora_B.speech.weight', 'model.layers.9.mlp.gate_up_proj.lora_A.speech.weight', 'model.layers.9.mlp.gate_up_proj.lora_B.speech.weight', 'model.layers.9.self_attn.o_proj.lora_A.speech.weight', 'model.layers.9.self_attn.o_proj.lora_B.speech.weight', 'model.layers.9.self_attn.qkv_proj.lora_A.speech.weight', 'model.layers.9.self_attn.qkv_proj.lora_B.speech.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "NUM_CALIBRATION_SAMPLES = 512\n",
    "MAX_SEQUENCE_LENGTH = 8192\n",
    "MODEL_ID = 'cutebananas/phi-4-multimodal-finetuned'\n",
    "\n",
    "\n",
    "# Load model and processor manually\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True,\n",
    "    attn_implementation='sdpa',\n",
    ")\n",
    "\n",
    "# ✅ 手动加载 processor（并绕过 llmcompressor 的自动 processor 初始化）\n",
    "processor = Phi4MMProcessor.from_pretrained(\"microsoft/Phi-4-multimodal-instruct\", trust_remote_code=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcd1f5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type: <class 'datasets.arrow_dataset.Dataset'>\n",
      "Sample: {'id': '21464a6831c1443db294d1b56a7a33a5_b8b9a4513c06454b9f66b09f50a539ae_6', 'image_paths': ['data/DriveLM_nuScenes/nuscenes/samples/CAM_FRONT/n015-2018-09-26-11-17-24+0800__CAM_FRONT__1537932304912461.jpg', 'data/DriveLM_nuScenes/nuscenes/samples/CAM_FRONT_LEFT/n015-2018-09-26-11-17-24+0800__CAM_FRONT_LEFT__1537932304904844.jpg', 'data/DriveLM_nuScenes/nuscenes/samples/CAM_FRONT_RIGHT/n015-2018-09-26-11-17-24+0800__CAM_FRONT_RIGHT__1537932304920339.jpg', 'data/DriveLM_nuScenes/nuscenes/samples/CAM_BACK/n015-2018-09-26-11-17-24+0800__CAM_BACK__1537932304937525.jpg', 'data/DriveLM_nuScenes/nuscenes/samples/CAM_BACK_LEFT/n015-2018-09-26-11-17-24+0800__CAM_BACK_LEFT__1537932304947423.jpg', 'data/DriveLM_nuScenes/nuscenes/samples/CAM_BACK_RIGHT/n015-2018-09-26-11-17-24+0800__CAM_BACK_RIGHT__1537932304927893.jpg'], 'conversations': [{'from': 'human', 'value': 'In this scenario, what are safe actions to take for the ego vehicle?'}, {'from': 'gpt', 'value': 'Keep going at the same speed, slightly offset to the left, or slightly offset to the right.'}]}\n"
     ]
    }
   ],
   "source": [
    "calib_dataset = load_from_disk(\"../data/DriveLM_nuScenes/split/train\")\n",
    "calib_dataset = calib_dataset.shuffle(seed=42).select(range(NUM_CALIBRATION_SAMPLES))\n",
    "print(\"Dataset type:\", type(calib_dataset))\n",
    "print(\"Sample:\", calib_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0820d2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = build_collate_fn(\"drivelm_nus_phi4_collate_fn_val\")\n",
    "val_collate_fn = partial(collate_fn, processor=processor, device='cuda')\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    calib_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=val_collate_fn,\n",
    "    num_workers=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "637671d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed dataset: {'id': '21464a6831c1443db294d1b56a7a33a5_b8b9a4513c06454b9f66b09f50a539ae_6', 'image_paths': ['data/DriveLM_nuScenes/nuscenes/samples/CAM_FRONT/n015-2018-09-26-11-17-24+0800__CAM_FRONT__1537932304912461.jpg', 'data/DriveLM_nuScenes/nuscenes/samples/CAM_FRONT_LEFT/n015-2018-09-26-11-17-24+0800__CAM_FRONT_LEFT__1537932304904844.jpg', 'data/DriveLM_nuScenes/nuscenes/samples/CAM_FRONT_RIGHT/n015-2018-09-26-11-17-24+0800__CAM_FRONT_RIGHT__1537932304920339.jpg', 'data/DriveLM_nuScenes/nuscenes/samples/CAM_BACK/n015-2018-09-26-11-17-24+0800__CAM_BACK__1537932304937525.jpg', 'data/DriveLM_nuScenes/nuscenes/samples/CAM_BACK_LEFT/n015-2018-09-26-11-17-24+0800__CAM_BACK_LEFT__1537932304947423.jpg', 'data/DriveLM_nuScenes/nuscenes/samples/CAM_BACK_RIGHT/n015-2018-09-26-11-17-24+0800__CAM_BACK_RIGHT__1537932304927893.jpg'], 'conversations': [{'from': 'human', 'value': 'In this scenario, what are safe actions to take for the ego vehicle?'}, {'from': 'gpt', 'value': 'Keep going at the same speed, slightly offset to the left, or slightly offset to the right.'}], 'text': '<image>\\nIn this scenario, what are safe actions to take for the ego vehicle?\\nKeep going at the same speed, slightly offset to the left, or slightly offset to the right.'}\n",
      "Tokenized dataset: {'input_ids': [27, 3365, 523, 637, 495, 25697, 11, 1412, 553, 7703, 10370, 316, 2304, 395, 290, 34243, 9540, 3901, 25627, 2966, 540, 290, 2684, 7733, 11, 16132, 8985, 316, 290, 3561, 11, 503, 16132, 8985, 316, 290, 1849, 13], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "def preprocess(example):\n",
    "    question = [x[\"value\"] for x in example[\"conversations\"] if x[\"from\"] == \"human\"]\n",
    "    answer = [x[\"value\"] for x in example[\"conversations\"] if x[\"from\"] == \"gpt\"]\n",
    "    q = question[0] if question else \"\"\n",
    "    a = answer[0] if answer else \"\"\n",
    "    return {\n",
    "        \"text\": f\"<image>\\n{q}\\n{a}\"\n",
    "    }\n",
    "\n",
    "dataset = calib_dataset.map(preprocess)\n",
    "print(\"Preprocessed dataset:\", dataset[0])\n",
    "tokenizer = processor.tokenizer\n",
    "\n",
    "# Step 2: Tokenize text（图像不用于 calibration）\n",
    "def tokenize(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        padding=False,\n",
    "        truncation=True,\n",
    "        max_length=MAX_SEQUENCE_LENGTH,\n",
    "        return_tensors=None,\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "\n",
    "dataset = dataset.map(tokenize, remove_columns=dataset.column_names)\n",
    "print(\"Tokenized dataset:\", dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f956a53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in calib_dataset: 512\n",
      "Example entry: {'id': '21464a6831c1443db294d1b56a7a33a5_b8b9a4513c06454b9f66b09f50a539ae_6', 'image_paths': ['data/DriveLM_nuScenes/nuscenes/samples/CAM_FRONT/n015-2018-09-26-11-17-24+0800__CAM_FRONT__1537932304912461.jpg', 'data/DriveLM_nuScenes/nuscenes/samples/CAM_FRONT_LEFT/n015-2018-09-26-11-17-24+0800__CAM_FRONT_LEFT__1537932304904844.jpg', 'data/DriveLM_nuScenes/nuscenes/samples/CAM_FRONT_RIGHT/n015-2018-09-26-11-17-24+0800__CAM_FRONT_RIGHT__1537932304920339.jpg', 'data/DriveLM_nuScenes/nuscenes/samples/CAM_BACK/n015-2018-09-26-11-17-24+0800__CAM_BACK__1537932304937525.jpg', 'data/DriveLM_nuScenes/nuscenes/samples/CAM_BACK_LEFT/n015-2018-09-26-11-17-24+0800__CAM_BACK_LEFT__1537932304947423.jpg', 'data/DriveLM_nuScenes/nuscenes/samples/CAM_BACK_RIGHT/n015-2018-09-26-11-17-24+0800__CAM_BACK_RIGHT__1537932304927893.jpg'], 'conversations': [{'from': 'human', 'value': 'In this scenario, what are safe actions to take for the ego vehicle?'}, {'from': 'gpt', 'value': 'Keep going at the same speed, slightly offset to the left, or slightly offset to the right.'}]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows in calib_dataset:\", len(calib_dataset))\n",
    "print(\"Example entry:\", calib_dataset[0] if len(calib_dataset) > 0 else \"EMPTY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ddcefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09T10:49:05.370771+0800 | reset | INFO - Compression lifecycle reset\n",
      "2025-05-09T10:49:05.371799+0800 | from_modifiers | INFO - Creating recipe from modifiers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/llmcompressor/modifiers/quantization/gptq/base.py:254: UserWarning: Falling back to layer_sequential pipeline\n",
      "  warnings.warn(\"Falling back to layer_sequential pipeline\")\n",
      "Preparing intermediates cache:   0%|          | 0/512 [00:00<?, ?it/s]\n",
      "/root/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/llmcompressor/modifiers/quantization/gptq/base.py:270: UserWarning: Falling back to basic pipeline, which requires extra memory and may result in decreased accuracy. Consider using `offload_hessians=True`\n",
      "  warnings.warn(\n",
      "Calibrating:   0%|          | 0/512 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "None is not a valid InputMode",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/llmcompressor/modifiers/quantization/gptq/base.py:234\u001b[0m, in \u001b[0;36mGPTQModifier.on_initialize\u001b[0;34m(self, state, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m     \u001b[43mrun_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msequential_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/llmcompressor/pipelines/sequential/pipeline.py:51\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[0;34m(model, dataloader, sequential_targets, ignore, callback_modifier)\u001b[0m\n\u001b[1;32m     50\u001b[0m sample_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(dataloader))\n\u001b[0;32m---> 51\u001b[0m subgraphs \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_subgraphs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequential_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m calibration_forward_context(model), DisableQuantization(model):\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# prepare intermediates cache\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/llmcompressor/pipelines/sequential/helpers.py:95\u001b[0m, in \u001b[0;36mtrace_subgraphs\u001b[0;34m(model, sample_input, sequential_targets, ignore)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m calibration_forward_context(model), HooksMixin\u001b[38;5;241m.\u001b[39mdisable_hooks():\n\u001b[1;32m     93\u001b[0m     graph \u001b[38;5;241m=\u001b[39m GraphModule(\n\u001b[1;32m     94\u001b[0m         model,\n\u001b[0;32m---> 95\u001b[0m         \u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdummy_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconcrete_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcomplete_concrete_args_with_inputs_not_in_dummy_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# bug in trace throws an error for variadic\u001b[39;49;00m\n\u001b[1;32m    101\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# args and kwargs in function signature\u001b[39;49;00m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    103\u001b[0m     )\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# copy metadata\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/llmcompressor/pipelines/sequential/helpers.py:161\u001b[0m, in \u001b[0;36mget_tracer.<locals>.SequentialTracer.trace\u001b[0;34m(self, root, *args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m patch_attr(\u001b[38;5;28mtype\u001b[39m(root), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m, unwrapped_forward):\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/transformers/utils/fx.py:1326\u001b[0m, in \u001b[0;36mHFTracer.trace\u001b[0;34m(self, root, concrete_args, dummy_inputs, complete_concrete_args_with_inputs_not_in_dummy_inputs)\u001b[0m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcrete_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/torch/fx/_symbolic_trace.py:843\u001b[0m, in \u001b[0;36mTracer.trace\u001b[0;34m(self, root, concrete_args)\u001b[0m\n\u001b[1;32m    837\u001b[0m         _autowrap_check(\n\u001b[1;32m    838\u001b[0m             patcher, module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autowrap_function_ids\n\u001b[1;32m    839\u001b[0m         )\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_node(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 843\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_arg(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m),),\n\u001b[1;32m    844\u001b[0m         {},\n\u001b[1;32m    845\u001b[0m         type_expr\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__annotations__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    846\u001b[0m     )\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmodule_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/cutebananas/phi-4-multimodal-finetuned/7d8df08510df91e50be6423f55ce9b845b13134d/modeling_phi4mm.py:2113\u001b[0m, in \u001b[0;36mPhi4MMForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, input_image_embeds, image_sizes, image_attention_mask, input_audio_embeds, audio_embed_sizes, audio_attention_mask, input_mode, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep)\u001b[0m\n\u001b[1;32m   2112\u001b[0m     input_mode \u001b[38;5;241m=\u001b[39m input_mode[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m-> 2113\u001b[0m input_mode \u001b[38;5;241m=\u001b[39m \u001b[43mInputMode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_mode \u001b[38;5;129;01min\u001b[39;00m [InputMode\u001b[38;5;241m.\u001b[39mVISION_SPEECH, InputMode\u001b[38;5;241m.\u001b[39mVISION]:\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/enum.py:384\u001b[0m, in \u001b[0;36mEnumMeta.__call__\u001b[0;34m(cls, value, names, module, qualname, type, start)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# simple value lookup\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__new__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;66;03m# otherwise, functional API: we're creating a new Enum type\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/enum.py:702\u001b[0m, in \u001b[0;36mEnum.__new__\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 702\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ve_exc\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: None is not a valid InputMode",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/llmcompressor/modifiers/quantization/gptq/base.py:256\u001b[0m, in \u001b[0;36mGPTQModifier.on_initialize\u001b[0;34m(self, state, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 256\u001b[0m     \u001b[43mrun_layer_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msequential_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/llmcompressor/pipelines/layer_sequential/pipeline.py:56\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[0;34m(model, dataloader, sequential_targets, callback_modifier)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m calibration_forward_context(model), DisableQuantization(model):\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# prepare intermediates cache\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     intermediates: IntermediatesCache \u001b[38;5;241m=\u001b[39m \u001b[43mcapture_first_layer_intermediates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     num_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(layers)\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/llmcompressor/pipelines/layer_sequential/helpers.py:76\u001b[0m, in \u001b[0;36mcapture_first_layer_intermediates\u001b[0;34m(model, first_layer, dataloader, mask_padding)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EarlyStopException \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/cutebananas/phi-4-multimodal-finetuned/7d8df08510df91e50be6423f55ce9b845b13134d/modeling_phi4mm.py:2113\u001b[0m, in \u001b[0;36mPhi4MMForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, input_image_embeds, image_sizes, image_attention_mask, input_audio_embeds, audio_embed_sizes, audio_attention_mask, input_mode, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep)\u001b[0m\n\u001b[1;32m   2112\u001b[0m     input_mode \u001b[38;5;241m=\u001b[39m input_mode[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m-> 2113\u001b[0m input_mode \u001b[38;5;241m=\u001b[39m \u001b[43mInputMode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_mode \u001b[38;5;129;01min\u001b[39;00m [InputMode\u001b[38;5;241m.\u001b[39mVISION_SPEECH, InputMode\u001b[38;5;241m.\u001b[39mVISION]:\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/enum.py:384\u001b[0m, in \u001b[0;36mEnumMeta.__call__\u001b[0;34m(cls, value, names, module, qualname, type, start)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# simple value lookup\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__new__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;66;03m# otherwise, functional API: we're creating a new Enum type\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/enum.py:702\u001b[0m, in \u001b[0;36mEnum.__new__\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 702\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ve_exc\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: None is not a valid InputMode",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m recipe \u001b[38;5;241m=\u001b[39m GPTQModifier(\n\u001b[1;32m      2\u001b[0m     targets\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinear\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     scheme\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW4A16\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     sequential_targets\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPhi4MMDecoderLayer\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m     ignore\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlm_head\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mre:model.vision_embed_tokens.*\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m \u001b[43moneshot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecipe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecipe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_SEQUENCE_LENGTH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_calibration_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_CALIBRATION_SAMPLES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Save model and processor\u001b[39;00m\n\u001b[1;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(SAVE_DIR, save_compressed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/llmcompressor/entrypoints/oneshot.py:179\u001b[0m, in \u001b[0;36moneshot\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moneshot\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PreTrainedModel:\n\u001b[1;32m    178\u001b[0m     one_shot \u001b[38;5;241m=\u001b[39m Oneshot(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 179\u001b[0m     \u001b[43mone_shot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m one_shot\u001b[38;5;241m.\u001b[39mmodel\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/llmcompressor/entrypoints/oneshot.py:131\u001b[0m, in \u001b[0;36mOneshot.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03mPerforms one-shot calibration.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m calibration_dataloader \u001b[38;5;241m=\u001b[39m get_calibration_dataloader(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor\n\u001b[1;32m    130\u001b[0m )\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_recipe_modifiers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcalibration_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalibration_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecipe_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecipe_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m post_process(\n\u001b[1;32m    136\u001b[0m     model_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_args,\n\u001b[1;32m    137\u001b[0m     recipe_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecipe_args,\n\u001b[1;32m    138\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dir,\n\u001b[1;32m    139\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/llmcompressor/entrypoints/oneshot.py:173\u001b[0m, in \u001b[0;36mOneshot.apply_recipe_modifiers\u001b[0;34m(self, calibration_dataloader, recipe_stage)\u001b[0m\n\u001b[1;32m    161\u001b[0m session_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    162\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    163\u001b[0m     recipe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecipe,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m     recipe_stage\u001b[38;5;241m=\u001b[39mrecipe_stage,\n\u001b[1;32m    170\u001b[0m )\n\u001b[1;32m    172\u001b[0m session\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 173\u001b[0m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msession_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m session\u001b[38;5;241m.\u001b[39mfinalize(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msession_kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/llmcompressor/core/session.py:118\u001b[0m, in \u001b[0;36mCompressionSession.initialize\u001b[0;34m(self, recipe, recipe_stage, recipe_args, model, teacher_model, optimizer, attach_optim_callbacks, train_data, val_data, test_data, calib_data, copy_data, start, steps_per_epoch, batches_per_step, loggers, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minitialize\u001b[39m(\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     70\u001b[0m     recipe: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecipe\u001b[39m\u001b[38;5;124m\"\u001b[39m, List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecipe\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     87\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ModifiedState:\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m    Initialize the session for compression. This will run the initialize method\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    for each modifier in the session's lifecycle. This will also set the session's\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    :return: the modified state of the session after initializing\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     mod_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lifecycle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrecipe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecipe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrecipe_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecipe_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrecipe_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecipe_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mteacher_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mteacher_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattach_optim_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattach_optim_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcalib_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalib_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatches_per_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatches_per_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloggers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloggers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ModifiedState(\n\u001b[1;32m    139\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    140\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moptimizer,\n\u001b[1;32m    141\u001b[0m         loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mloss,\n\u001b[1;32m    142\u001b[0m         modifier_data\u001b[38;5;241m=\u001b[39mmod_data,\n\u001b[1;32m    143\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/llmcompressor/core/lifecycle.py:105\u001b[0m, in \u001b[0;36mCompressionLifecycle.initialize\u001b[0;34m(self, recipe, recipe_stage, recipe_args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m mod_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodifiers:\n\u001b[0;32m--> 105\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialized modifier: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, mod)\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/llmcompressor/modifiers/stage.py:83\u001b[0m, in \u001b[0;36mStageModifiers.initialize\u001b[0;34m(self, state, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m accelerator \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccelerator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m modifier \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodifiers:\n\u001b[0;32m---> 83\u001b[0m     \u001b[43mmodifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accelerator:\n\u001b[1;32m     85\u001b[0m         accelerator\u001b[38;5;241m.\u001b[39mwait_for_everyone()\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/llmcompressor/modifiers/modifier.py:90\u001b[0m, in \u001b[0;36mModifier.initialize\u001b[0;34m(self, state, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalized_:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot initialize a modifier that has already been finalized\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m     )\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialized_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# trigger start\u001b[39;00m\n\u001b[1;32m     93\u001b[0m fake_start_event \u001b[38;5;241m=\u001b[39m Event(type_\u001b[38;5;241m=\u001b[39mEventType\u001b[38;5;241m.\u001b[39mBATCH_START, global_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/llmcompressor/modifiers/quantization/gptq/base.py:275\u001b[0m, in \u001b[0;36mGPTQModifier.on_initialize\u001b[0;34m(self, state, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[1;32m    270\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFalling back to basic pipeline, which requires extra memory and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmay result in decreased accuracy. Consider using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`offload_hessians=True`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m )\n\u001b[0;32m--> 275\u001b[0m \u001b[43mrun_basic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalib\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/llmcompressor/pipelines/basic/pipeline.py:41\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[0;34m(model, dataloader, callback_modifier)\u001b[0m\n\u001b[1;32m     39\u001b[0m     batch \u001b[38;5;241m=\u001b[39m apply_pad_mask_to_batch(batch)\n\u001b[1;32m     40\u001b[0m     batch \u001b[38;5;241m=\u001b[39m tensors_to_device(batch, model_device)\n\u001b[0;32m---> 41\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# TODO: replace with a lifecycle event\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callback_modifier:\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/cutebananas/phi-4-multimodal-finetuned/7d8df08510df91e50be6423f55ce9b845b13134d/modeling_phi4mm.py:2113\u001b[0m, in \u001b[0;36mPhi4MMForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, input_image_embeds, image_sizes, image_attention_mask, input_audio_embeds, audio_embed_sizes, audio_attention_mask, input_mode, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep)\u001b[0m\n\u001b[1;32m   2111\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(input_mode) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2112\u001b[0m     input_mode \u001b[38;5;241m=\u001b[39m input_mode[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m-> 2113\u001b[0m input_mode \u001b[38;5;241m=\u001b[39m \u001b[43mInputMode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_mode \u001b[38;5;129;01min\u001b[39;00m [InputMode\u001b[38;5;241m.\u001b[39mVISION_SPEECH, InputMode\u001b[38;5;241m.\u001b[39mVISION]:\n\u001b[1;32m   2116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_lora_adapter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvision\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/enum.py:384\u001b[0m, in \u001b[0;36mEnumMeta.__call__\u001b[0;34m(cls, value, names, module, qualname, type, start)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03mEither returns an existing member, or creates a new enum class.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m`type`, if set, will be mixed in as the first base class.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# simple value lookup\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__new__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;66;03m# otherwise, functional API: we're creating a new Enum type\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_create_(\n\u001b[1;32m    387\u001b[0m         value,\n\u001b[1;32m    388\u001b[0m         names,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m         start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[1;32m    393\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/DriveVLMs/lib/python3.9/enum.py:702\u001b[0m, in \u001b[0;36mEnum.__new__\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m    700\u001b[0m ve_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m is not a valid \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (value, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m))\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 702\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ve_exc\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    705\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m._missing_: returned \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m instead of None or a valid member\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    706\u001b[0m             \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, result)\n\u001b[1;32m    707\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: None is not a valid InputMode"
     ]
    }
   ],
   "source": [
    "recipe = GPTQModifier(\n",
    "    targets=\"Linear\",\n",
    "    scheme=\"W4A16\",\n",
    "    sequential_targets=[\"Phi4MMDecoderLayer\"],\n",
    "    ignore=[\"lm_head\", \"re:model.vision_embed_tokens.*\"],\n",
    ")\n",
    "\n",
    "\n",
    "oneshot(\n",
    "    model=model,\n",
    "    dataset=dataset,  \n",
    "    recipe=recipe,\n",
    "    max_seq_length=MAX_SEQUENCE_LENGTH,\n",
    "    num_calibration_samples=NUM_CALIBRATION_SAMPLES,\n",
    "    trust_remote_code_model=True,\n",
    "    processor=processor,  \n",
    "    \n",
    ")\n",
    "# Save model and processor\n",
    "model.save_pretrained(SAVE_DIR, save_compressed=True)\n",
    "processor.save_pretrained(SAVE_DIR)\n",
    "model.to(\"cuda\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DriveVLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
